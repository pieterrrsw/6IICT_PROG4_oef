{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1> <center> Gebaseerd op een cursus van:</center> </h1> \n",
    "    </font>\n",
    "    <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>1. Regelgebaseerde (AI) Sentimentanalyse</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#013220\">\n",
    "Taaltechnologen doen steeds meer een beroep op machine learning-modellen om bij gegeven teksten onderzoek te doen naar sentimentwoorden. De basis van deze modellen is echter te vinden in de <b>regelgebaseerde (AI) sentimentanalyse</b>. In deze notebook maak je daarom kennis met deze regelgebaseerde analyse.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\">\n",
    "Om deze Notebook te volgen moet je een basiskennis hebben van Strings, Lists en Dictionaries. Stel zeker vragen als je tijdens het doorlopen van deze Notebook met vragen zit.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h2>2. Principe van Sentimentanalyse</h2> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentimentanalyse maakt gebruik van een **lexicon** (= woordenboek) met daarin woorden gekoppeld aan hun **sentiment** (positief, negatief of neutraal), dus eigenlijk een woordenboek van sentimentwoorden. \n",
    "\n",
    "'Blij' bijvoorbeeld heeft een positieve polariteit, 'thuisbankieren' een neutrale en 'boos' een negatieve polariteit. In het lexicon wordt het sentiment weergegeven door een kommagetal (Float) tussen -2 en 2. Een strikt positief getal komt overeen met een positief sentiment, een strikt negatief getal met een negatief sentiment en 0 met een neutraal sentiment. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../_afbeeldingen/schaal.png\" alt=\"Banner\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:40%\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het sentiment van een tekst wordt bepaald door de som te nemen van alle sentimentwoorden in deze tekst."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor je sentimentwoorden uit een lexicon kunt matchen met de gegeven tekst (de data) moet je de data \n",
    "-  *inlezen*; \n",
    "-  *preprocessen*, d.w.z. voorverwerken zodat je het kan vergelijken met de woorden uit het lexicon. \n",
    "\n",
    "Preprocessing omvat alle stappen die nodig zijn om de data voor te bereiden op wat volgt. Namelijk het vergelijken met het lexicon. **Preprocessing is een zeer belangrijke stap**. Woorden kunnen namelijk op veel verschillende manieren geschreven en vervoegd worden. <br><br>Hieronder vind je een oplijsting van veelvoorkomende preprocessing stappen.\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "1. **Lowercasing:** alle hoofdlettertekens worden vervangen door kleine letters. Lowercasing is nodig omdat de woorden in een lexicon staan zonder hoofdletters.\n",
    "2. **Tokenisering:** alle zinnen worden in betekenisvolle eenheden of 'tokens' gesplitst, zoals woorden en leestekens. Deze splitsing gebeurt op basis van de aanwezige spaties in de zinnen.\n",
    "3. **Woordsoort tagging:** aan elk token wordt toegekend wat het is, zoals adjectief of symbool. Sommige woorden kunnen bv. als zelfstandig EN als bijvoeglijk naamwoord voorkomen. Zo'n woord kan ook een andere sentimentwaarde hebben naargelang zijn woordsoort. De woordsoorten van het lexicon staan in het Engels. Dit is noodzakelijk voor de lerende (ML) sentimentanalyse.\n",
    "4. **Lemmatisering:** alle tokens worden omgezet naar hun meest algemene vorm (= lemma of woordenboekvorm). Zo wordt \"katten\"-->\"kat\" of \"gekund\"-->\"kunnen\".\n",
    "\n",
    "Tenslotte kan deze algemene vorm van deze tokens opgezocht worden in het lexicon. De som van alle tokens bepaald het sentiment van de tekst. Onderstaande afbeelding toont een schematische weergave van dit proces."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"pre\"></span>\n",
    "<div>\n",
    "<img src=\"../_afbeeldingen/sentiment.png\" alt=\"Banner\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 10px; width:90%\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld:\n",
    "Gegeven zin:    \n",
    "De spelletjes waren toffe ijsbrekers.\n",
    "\n",
    "1. Lowercasing: de spelletjes waren toffe ijsbrekers.\n",
    "\n",
    "2. Tokens: 'de' 'spelletjes' 'waren' 'toffe' 'ijsbrekers' '.' \n",
    "\n",
    "3. Woordsoort: \n",
    "    -  'de': lidwoord (DET);\n",
    "    -  'spelletjes': naamwoord (NOUN); \n",
    "    -  'waren': hulpwerkwoord (AUX);\n",
    "    -  'toffe': adjectief (ADJ);\n",
    "    -  'ijsbrekers': naamwoord (NOUN);\n",
    "    -  '.': leesteken (SYM). <br> <br>\n",
    "4. Lemma's: 'de', 'spel', 'zijn', 'tof', 'ijsbreker', '.'\n",
    "\n",
    "Sentiment van de tekst:\n",
    "-  De sentimenten van de lemma's worden opgezocht in het lexicon. Didwoorden/leestekens zijn altijd neutraal.\n",
    "-  'spel' heeft polariteit 1, 'zijn' heeft polariteit 0, 'tof' heeft polariteit 0,8 en 'ijsbreker' 0.\n",
    "-  Het sentiment van de gegeven zin is de som van deze sentimenten, dus 1,8. \n",
    "-  1,8 is een positief getal. De zin roept een positief sentiment op. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;margin-bottom:-35px;'>\n",
    "    <h2>3. Modules importeren</h2> \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu je dit weet, kun je bijna aan de slag. Je laadt eerst twee Python-modules in. Voer daartoe de code-cel hieronder uit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules importeren\n",
    "import json                       # voor lexicon\n",
    "import string                     # voor opsomming leestekens  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h2>4. Lexicon inlezen</h3> \n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>4.1 Opbouw Lexicon</h3> \n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer de code-cellen hieronder uit. Dit verschaft je meer info over de opmaak van het Lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon inlezen. Zorg dat het pad correct is (hoofdmap is hfst_5_AI)!\n",
    "with open(\"lexicondict.json\", \"rb\") as file: # bestand lexicondict.json in map data bevat het sentimentlexicon\n",
    "    lexicon = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatype van lexicon\n",
    "print(type(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aantal elementen in lexicon\n",
    "print(len(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# toon tien elementen van lexicon\n",
    "lijst_keys = list(lexicon)[0:9]\n",
    "for key in lijst_keys:\n",
    "    print(f\"{key}: {lexicon[key]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000065\"> \n",
    "    Het lexicon is een <b>dictionary</b> met 10938 woorden. Het lexicon geeft de woordsoort (adjectief, lidwoord, ...) en het sentiment van de woorden in het lexicon.<br><br>\n",
    "    De woorden in het lexicon zijn de <b>keys</b> van de dictionary.\n",
    "    De <b>values</b> van deze dictionary zijn opnieuw een dictionary met als <b>key</b> de \"woordsoort\" en overeenkomstige <b>value</b> de \"sentimentscore\". Sommige woorden hebben meerdere woordsoorten. Zo is <b>fout</b> zowel een adjectief (ADJ) als naamwoord (NOUN).\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit bovenstaande code leid je bijvoorbeeld af:\n",
    "-  het woord 'retorisch' is een adjectief dat qua sentiment neutraal is;\n",
    "-  het woord 'gezwind' is een adjectief dat qua sentiment positief is;\n",
    "-  het woord 'evenwichtig' is een adjectief dat positief is, positiever zelfs dan 'gezwind';\n",
    "-  het woord 'fout' kan zowel een adjectief als een naamwoord zijn, beide met een negatief sentiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan het lexicon ook weergeven in de vorm van een tabel:<br><br>\n",
    "\n",
    "<table align=\"center\">\n",
    " <thead align=\"center\">\n",
    "    <tr>\n",
    "      <td>woord</td>\n",
    "      <td>postag</td>\n",
    "      <td>polarity</td>\n",
    "     </tr>    \n",
    "  </thead>\n",
    "  <tbody align=\"center\">  \n",
    "      <tr> <td> retorisch </td>   <td> ADJ </td> <td> 0.0 </td>  </tr> \n",
    "      <tr> <td> gezwind </td>     <td> ADJ </td> <td> 0.6 </td>  </tr> \n",
    "      <tr> <td> evenwichtig </td> <td> ADJ </td> <td> 1.25 </td>  </tr> \n",
    "      <tr> <td> modaal </td>      <td> ADJ </td> <td> 0.3 </td>  </tr> \n",
    "      <tr> <td> digitaal </td>    <td> ADJ </td> <td> 0.0 </td> </tr> \n",
    "      <tr> <td> fout </td>        <td> ADJ </td> <td> -0.5 </td> </tr> \n",
    "      <tr> <td> fout </td>        <td> NOUN </td> <td> -2.0 </td> </tr> \n",
    "    </tbody>           \n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"info_ophalen\" style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>4.2 Info ophalen uit Lexicon (via Python)</h3> \n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan aan de hand van Python-code de woordsoort en het sentiment van een woord opzoeken in het lexicon.<br>\n",
    "Als voorbeeld (uitgaande van variabelnaam `lexicon`):\n",
    "-  `lexicon[\"retorisch\"].keys()` heeft als uitvoer `['ADJ']`\n",
    "-  `lexicon[\"retorisch\"].values()` heeft als uitvoer `[0.0]`\n",
    "-  `lexicon[\"fout\"].keys()` heeft als uitvoer `['ADJ', 'NOUN']`\n",
    "-  `lexicon[\"fout\"].values()` heeft als uitvoer `[-0.5, -2.0]`\n",
    "\n",
    "Test dit uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[\"retorisch\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[\"retorisch\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[\"fout\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[\"fout\"].values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 4.1:\n",
    "\n",
    "Zoek op in het lexicon:\n",
    "-  de woordsoort(en) van 'kwekkebekken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  de woordsoort(en) van  'aanraden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  De sentimentscore(s) van 'jolijt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  de sentimentscore(s) van 'konkelen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- de sentimentscore van het naamwoord (NOUN) 'schoon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: print eerst lexicon[\"schoon\"], wat is de output?\n",
    "#      Hoe kan je nu de score bij de key \"NOUN\" printen?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Bedenk dat je gewoonweg in een dictionary bezig bent. Je kan dus nagaan of een woord zich als sleutel in de dictionary bevindt. Gebruik hiervoor <b>het keywoord in</b> of <b>de methode get</b>. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"zieke\" in lexicon)\n",
    "print(\"boos\" in lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lexicon.get(\"zieke\", \"Staat niet in lexicon\"))\n",
    "print(lexicon.get(\"boos\", \"Staat niet in lexicon\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 4.2:\n",
    "\n",
    "Zoek een woord dat niet in het lexicon staat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h2>5. Preprocessing</h2> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "Nu het lexicon ingelezen is, is het tijd om deze te verwerken (preprocessen). Herinner je dat dit uit vier stappen bestond. Klik <a href=#pre>HIER</a> om terug te springen.\n",
    "</div>\n",
    "\n",
    "1. **Lowercasing**: zet alles in kleine letters.\n",
    "2. **Tokenisering**: scheid alle woorden, leestekens en symbolen.\n",
    "3. **woordsoort tagging**: geef ieder woord, leesteken en symbool een categorie.\n",
    "4. **Lemmatisering**: schrijf ieder woord in zijn basisvorm.\n",
    "\n",
    "We zullen deze stappen doorlopen op basis van een `klantenreview`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>5.0 Inlezen review</h3> \n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer volgende code-cellen uit om de review in te lezen en vervolgens te bekijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Nieuw concept in Gent, maar dat kan volgens mij toch beter. De meeste cornflakes waren gewoon de basic soorten. Ook wat duur voor de hoeveelheid die je krijgt, vooral met de toppings zijn ze zuinig. En als je ontbijt aanbiedt, geef de mensen dan toch ook wat meer keuze voor hun koffie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>5.1 Lowercasing</h3> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.1:\n",
    "\n",
    "Zet de tekst in de variabele `review` om naar lowercasing. Sla het resultaat op in de variabele `review_kleineletters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zet tekst van de review om naar tekst in kleine letters\n",
    "review_kleineletters =  # Vul aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toon resultaat van lowercasing (er mag geen hoofdletter meer in de review staan)\n",
    "print(review_kleineletters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>5.2 Tokenisering</h3> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu zal je de review in woorden, leestekens en symbolen opsplitsen m.b.v. de computer, dat gebeurt op basis van spaties. Deze gescheiden elementen zijn **tokens**.\n",
    "\n",
    "Om tokens automatisch te genereren, kijken we naar spaties. Het is namelijk eenvoudig om te zeggen dat ieder element na een spatie een nieuw token is. \n",
    "\n",
    "Hier is echter wel een probleem. Sommige woorden en leestekens staan aan elkaar vast. Deze moeten dus eerst met een spatie gescheiden worden. Bv. Hello world! wordt eerst geschreven als Hello world ! en de drie tokens zijn dan:<br> 'Hello', 'world' en '!'.\n",
    "\n",
    "Je zal de review dus eerst wat moeten aanpassen: voor en na elk leesteken moet zeker een spatie aanwezig zijn.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.2:\n",
    "\n",
    "Zet spaties tussen alle tokens in de variabele `review_kleineletters`. Sla het resultaat op in de variabele `tokens`. \n",
    "\n",
    "Alle mogelijke leestekens zijn terug te vinden in de variabele `leestekens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabele met erin alle leestekens\n",
    "leestekens = string.punctuation\n",
    "print(leestekens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: overloop ieder karakter in de string `review_kleineletters`. \n",
    "-  Is het een gewone letter? Voeg het toe aan `review_tokens`.\n",
    "-  Is het een leesteken? Zet eerst een spatie voor het teken, en voeg het daarna toe aan `review_tokens`.\n",
    "\n",
    "Gebruik **(not) in** om te controleren of een element niet/wel in de variabele **leestekens** voorkomt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_spaties = \"\"     # lege string, zet hierin review_kleineletters met spaties tussen alle elementen.\n",
    "for karakter in review_kleineletters:\n",
    "    # Vul aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# toon resultaat van spaties toevoegen\n",
    "print(review_spaties)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Ga pas verder als bovenstaande een spatie heeft tussen ieder <b>element</b>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu ieder element gescheiden is door een spatie, kunnen we de zin omvormen naar tokens. Splits de string op, op basis van de spaties. Het resultaat moet een **lijst met tokens** zijn (zie voorbeeld iets verderop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tokens = # Vul aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "    Ga pas verder als bovenstaande print volgend resultaat geeft:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['nieuw', 'concept', 'in', 'gent', ',', 'maar', 'dat', 'kan', 'volgens', 'mij', 'toch', 'beter', '.', 'de', 'meeste', 'cornflakes', 'waren', 'gewoon', 'de', 'basic', 'soorten', '.', 'ook', 'wat', 'duur', 'voor', 'de', 'hoeveelheid', 'die', 'je', 'krijgt', ',', 'vooral', 'met', 'de', 'toppings', 'zijn', 'ze', 'zuinig', '.', 'en', 'als', 'je', 'ontbijt', 'aanbiedt', ',', 'geef', 'de', 'mensen', 'dan', 'toch', 'ook', 'wat', 'meer', 'keuze', 'voor', 'hun', 'koffie', '.']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>5.3 Woordsoort tagging</h3> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als de tekst getokeniseerd is, kan je aan elk token een **woordsoort tag** toekennen. Dit is belangrijk omdat sommige woorden meerdere tags bezitten. Sommige woorden kunnen bijvoorbeeld als substantief én als adjectief gebruikt worden. Dit met een andere sentimentscore. De **woordsoort tag** toekennen is dus noodzakelijk om een correcte score te bekomen. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.3:\n",
    "\n",
    "Wat voor tag(s) hebben volgende woorden?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nieuw**: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concept**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**in**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopelijk merk je dat het taggen van woorden geen fijn proces is. Om de review te kunnen verwerken, moet je ieder woord labellen met de correcte woordsoort. Om jullie dit werk te besparekn, geeft onderstaande lijst `tags` de woordsoorten voor de volledige review. De **positie van de tags** komt overeen met de **positie van de tokens** uit 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['ADJ', 'NOUN', 'ADP', 'PROPN', 'SYM', 'CCONJ', 'PRON', 'VERB', 'ADP', 'PRON', 'ADV', 'ADJ', 'SYM', 'DET', 'ADV', 'NOUN', 'AUX', 'ADJ', 'DET', 'ADJ', 'NOUN', 'SYM', 'ADV', 'DET', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'PRON', 'AUX', 'SYM', 'ADV', 'ADP', 'DET', 'NOUN', 'AUX', 'PRON', 'ADJ', 'SYM', 'CCONJ', 'SCONJ', 'PRON', 'NOUN', 'AUX', 'SYM', 'VERB', 'DET', 'NOUN', 'ADV', 'ADV', 'ADV', 'PRON', 'DET', 'NOUN', 'ADP', 'PRON', 'NOUN', 'SYM', 'SYM', 'SYM']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h3>5.4 Lemmatisering</h3> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een token opzoeken in het lexicon doe je in zijn woordenboekgedaante. Elk token moet dus gelemmatiseerd worden, m.a.w. teruggebracht worden naar zijn **lemma** of woordenboekvorm, zoals enkelvoud voor een naamwoord en de infinitief voor een werkwoord. Het opzoeken van zo'n woordenboekvorm in het lexicon kan dan **geautomatiseerd** worden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net zoals bij <font color=#690027 markdown=\"1\"> 5.3 Woordsoort tagging en lemmatisering </font>, moet je ieder woord voorzien (labellen) met het juiste lemma. Om jullie dit werk te besparen, kunnen jullie onderstaande lijst `lemmas` gebruiken.  De **positie van de lemmas** komt overeen met de **positie van de tokens** uit 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = ['nieuw', 'concept', 'in', 'gent', ',', 'maar', 'dat', 'kunnen', 'volgens', 'mij', 'toch', 'goed', '.', 'de', 'veel', 'cornflakes', 'zijn', 'gewoon', 'de', 'basic', 'soort', '.', 'ook', 'wat', 'duur', 'voor', 'de', 'hoeveelheid', 'die', 'je', 'krijgen', ',', 'vooral', 'met', 'de', 'topping', 'zijn', 'ze', 'zuinig', '.', 'en', 'als', 'je', 'ontbijt', 'aanbieden', ',', 'geven', 'de', 'mens', 'dan', 'toch', 'ook', 'wat', 'meer', 'keuze', 'voor', 'hun', 'koffie', '.', '.', '.']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het opstellen van de lemmas ben je klaar met **preprocessing**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.4:\n",
    "Doorloop de eerste tien elementen in de lijst `lemmas`. Welke verschillen zijn er met de elementen uit de lijst `tokens`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toon eerste tien tokens en lemmas van deze tokens\n",
    "for i in range(10):\n",
    "    print(f\"{review_tokens[i]} | {lemmas[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "    In het volgende deel zal je de variabelen `tags` en `lemmas` gebruiken. De variabele `tokens` is niet nodig!\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h2>6. Sentiment lexicon matching</h2> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de variabelen `tags` en `lemmas` is het mogelijk om de sentimentscore van de tekst te bepalen. Dit door de lemma met de overeenkomstige tag op te zoeken in het `lexicon`.\n",
    "\n",
    "Stel dat we de sentimentscore van het lemma 'nieuw' willen bepalen. Deze heeft als tag 'ADJ'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lexicon[\"nieuw\"][\"ADJ\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is nu aan jullie om dit te doen voor ieder tag/lemma-paar in de lijsten `tags`/`lemmas`.<br> Je moet er wel mee rekening houden dat een tag/lemma-paar niet per se in de dictionary `lexicon` aanwezig is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 6.1\n",
    "Nu je review *gepreprocessed (voorverwerkt)* is, kan je het **sentiment bepalen** met behulp van het **lexicon** van sentimentwoorden dat je ter beschikking hebt (in de variabele `lexicon`). Het is dus de bedoeling dat je ieder element in `lemmas` en `tags` overloopt. Staat de combo in `lexicon`? Voeg dan de sentimentwaarde toe aan de variabele `sentiment_score`. We willen de som weten van alle sentimentwaarden!\n",
    "\n",
    "Je kan als volgt te werk gaan om de sentimentscore te berekenen. Voor ieder element in `lemmas` en `tags`:\n",
    "- Staat de **lemma** van dit element in `lexicon` (gebruik **keywoord in**)? Zo ja...\n",
    "- Heeft deze **lemma** in `lexicon` de overeenkomstige **woordsoort**? Zo ja... \n",
    "- Bepaal de overeenkomstige sentimentwaarde en tel deze op bij de teller `sentiment_score`.\n",
    "\n",
    "Als voorbeeld voor het lemma '**krijgen**', met als tag '**VERB**':\n",
    "- staat '**krijgen**' in het lexicon? JA\n",
    "- Heeft '**krijgen**' in het lexicon de woordsoort '**VERB**'? JA\n",
    "- Dit element heeft een sentimentwaarde van 0.0. Tel deze waarde op bij `sentiment_score`.\n",
    "\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Bovenstaand stappenplan gebruikt het <b>keywoord in</b>, hiernaast is er ook de <b>methode get</b>. Zou get gebruiken, makkelijker zijn?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score = 0\n",
    "for index, lemma in enumerate(lemmas):\n",
    "    # Vul aan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan onderstaande code gebruiken om een zin te printen bij de bekomen sentiment_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eindbeslissing voor deze review\n",
    "if sentiment_score > 0:\n",
    "    sentiment = \"positief\"\n",
    "elif sentiment_score == 0:\n",
    "    sentiment = \"neutraal\"\n",
    "elif sentiment_score < 0:\n",
    "    sentiment = \"negatief\"\n",
    "print(f\"De sentimentscore van de review is: {sentiment_score}\")\n",
    "print(\"Het sentiment van de review is dus \" + sentiment + \".\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 6.2\n",
    "Sommige zaken verliepen reeds geautomatiseerd, sommige moest je manueel doen. Lijst eens op wat manueel gebeurde en wat automatisch.\n",
    "\n",
    "**Antwoord automatisch**:\n",
    "\n",
    "**Antwoord manueel**:\n",
    "\n",
    "De manuele zaken zijn gegeven aan jullie. Deze zelf doen zou te veel tijd kosten, het is dan ook nog niet praktisch om andere reviews te verwerken. In het volgende deel **3_ML_sentiment.ipynb**. Zullen we zien hoe de zaken die momenteel manueel zijn, ook te automatiseren."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#013220\">\n",
    "Proficiat, je hebt geleerd hoe een regelgebaseerd systeem voor sentimentanalyse werkt!\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "\n",
    "Deze Notebook is gebaseerd op: Notebook Sentimentanalyseregelgebaseerd, zie <a href=\"http://www.aiopschool.be\">AI Op School</a>, van S. Pletinck , F. wyffels & N. Gesquière is in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "les_venv",
   "language": "python",
   "name": "les_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c58c2aa7d0668be41d779b9c0aeac89fa7edcfbcb9dd7a969e06833ff6090700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
